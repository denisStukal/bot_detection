?as.Date
predates <- as.character(as.Date(as.Date('2015-01-01', '%Y-%m-%d') : as.Date('2016-10-31', '%Y-%m-%d'),
origin = as.Date('1970-01-01', '%Y-%m-%d')))
predates
alldates <- unique(c(postdates, predates))
alldates
rm(list = ls())
names <- c('marcorubio', 'mcmullin', 'misc', 'others', 'protests', 'rumors', 'tedcruz', 'general')
postdates <- c('2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30',
'2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31')
predates <- c('2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31',
'2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29',
'2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-18')
alldates <- unique(c(postdates, predates))
alldates
alldates <- unique(c(postdates, predates))[order(unique(c(postdates, predates)))]
alldates
rm(list = ls())
names <- c('marcorubio', 'mcmullin', 'misc', 'others', 'protests', 'rumors', 'tedcruz', 'general')
postdates <- c('2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30',
'2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31')
predates <- c('2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31',
'2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29',
'2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-18')
alldates <- unique(c(postdates, predates))[order(unique(c(postdates, predates)))]
#-------------------------- Generate .py and .s for post Oct 10, 2016
for (n in names) {
for (dat in alldates) {
year <- substr(x = dat, start = 1, stop = 4)
month <- substr(x = dat, start = 6, stop = 7)
day <- substr(x = dat, start = 9, stop = 10)
if (n %in% postdates) {
where_out = 'post'
where_in = 'data'
} else {
if (n %in% predates) {
where_out = 'pre'
where_in = 'pre_october_2016'
} else {
cat('\n\nERROR: NOWHERE\n\n')
}
}
string1 <- paste0("import os, json, glob, datetime, shutil
from urllib.parse import urlparse
from multiprocessing import Pool
from tqdm import tqdm as tqdm
from smappdragon import JsonCollection
def get_date_from_file(f):
base = os.path.basename(f)
date = datetime.datetime.strptime(base.split('__')[1],'%m_%d_%Y')
return date
def get_files_to_filter(files):
files_to_sample = []
for f in tqdm(files):
basename = os.path.basename(f)
if '_pre' not in basename:
try:
f_date = get_date_from_file(f)
if START_DATE <= f_date <= END_DATE:
files_to_sample.append(f)
except:
pass
return files_to_sample
def is_from_troll(tweet):
if isinstance(tweet, dict) and tweet:
# Check if user is a troll.
if tweet['user']['id_str'] in TROLL_IDS:
return True
return False
def get_output_filepath(f):
collection_name = f.split('/')[3]
f_basename = os.path.basename(f).replace('.bz2', '')
new_collection_dir = os.path.join(OUT_DIR, collection_name)
os.makedirs(new_collection_dir, exist_ok=True)
shutil.chown(new_collection_dir, group='smapp')
f_out = os.path.join(new_collection_dir, f_basename)
return f_out
def filter_files(f):
date = get_date_from_file(f)
print('Working on {}'.format(date))
collect = JsonCollection(f, compression='bz2', throw_error=False, verbose=1)
collect.set_custom_filter(is_from_troll)
f_out = get_output_filepath(f)
with open(f_out, 'w+') as filehandle:
for tweet in collect.get_iterator():
try:
filehandle.write(json.dumps(tweet) + '''\n''')
except Exception as e:
#print(e)
pass
shutil.chown(f_out, group='smapp')
if __name__ == '__main__':
START_DATE = datetime.datetime.strptime('", year, "-", month, "-01', '%Y-%m-%d')
END_DATE = datetime.datetime.strptime('", year, "-", month, "-", day, "', '%Y-%m-%d')
OUT_DIR = '/scratch/ds3918/trolls/'
SEARCH_PATTERN = '/scratch/olympus/us_election_", n, "_2016/", where_in, "/us_election_", n, "_2016*'
TROLL_IDS = set()
print('START')
with open('/scratch/ds3918/trolls/data/all_troll_ids.txt', 'r') as inp:
for el in inp:
TROLL_IDS.add(el.strip())
print('There are {0} ids in TROLL_IDS'.format(len(TROLL_IDS)))
files = glob.glob(SEARCH_PATTERN)
files_to_sample = get_files_to_filter(files)
print('{} files to filter'.format(len(files_to_sample)))
for fi in files_to_sample:
filter_files(fi)
print('JOB DONE')")
string2 <- paste0("#!/bin/bash
#
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=10:00:00
#SBATCH --mem=5GB
#SBATCH --job-name=", n, "_", year, "_", month, "
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ds3918@nyu.edu
#SBATCH --output=logs/", n, "_", year, "_", month, ".out
cd /scratch/ds3918/trolls/code
LANG=en_US.utf8
PYTHONIOENCODING=UTF-8 python ", n, "_", year, "_", month, ".py > logs/output_", n, "_", year, "_", month, ".txt
exit 0;")
write(x = string1, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.py'))
write(x = string2, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.s'))
}
}
rm(list = ls())
names <- c('marcorubio', 'mcmullin', 'misc', 'others', 'protests', 'rumors', 'tedcruz', 'general')
rm(list = ls())
names <- c('marcorubio', 'mcmullin', 'misc', 'others', 'protests', 'rumors', 'tedcruz', 'general', 'trump', 'hillary')
postdates <- c('2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30',
'2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31')
predates <- c('2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31',
'2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29',
'2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-18')
alldates <- unique(c(postdates, predates))[order(unique(c(postdates, predates)))]
#-------------------------- Generate .py and .s for post Oct 10, 2016
for (n in names) {
for (dat in alldates) {
year <- substr(x = dat, start = 1, stop = 4)
month <- substr(x = dat, start = 6, stop = 7)
day <- substr(x = dat, start = 9, stop = 10)
if (dat %in% postdates) {
where_out = 'post'
where_in = 'data'
} else {
if (dat %in% predates) {
where_out = 'pre'
where_in = 'pre_october_2016'
} else {
cat('\n\nERROR: NOWHERE\n\n')
}
}
string1 <- paste0("import os, json, glob, datetime, shutil
from urllib.parse import urlparse
from multiprocessing import Pool
from tqdm import tqdm as tqdm
from smappdragon import JsonCollection
def get_date_from_file(f):
base = os.path.basename(f)
date = datetime.datetime.strptime(base.split('__')[1],'%m_%d_%Y')
return date
def get_files_to_filter(files):
files_to_sample = []
for f in tqdm(files):
basename = os.path.basename(f)
if '_pre' not in basename:
try:
f_date = get_date_from_file(f)
if START_DATE <= f_date <= END_DATE:
files_to_sample.append(f)
except:
pass
return files_to_sample
def is_from_troll(tweet):
if isinstance(tweet, dict) and tweet:
# Check if user is a troll.
if tweet['user']['id_str'] in TROLL_IDS:
return True
return False
def get_output_filepath(f):
collection_name = f.split('/')[3]
f_basename = os.path.basename(f).replace('.bz2', '')
new_collection_dir = os.path.join(OUT_DIR, collection_name)
os.makedirs(new_collection_dir, exist_ok=True)
shutil.chown(new_collection_dir, group='smapp')
f_out = os.path.join(new_collection_dir, f_basename)
return f_out
def filter_files(f):
date = get_date_from_file(f)
print('Working on {}'.format(date))
collect = JsonCollection(f, compression='bz2', throw_error=False, verbose=1)
collect.set_custom_filter(is_from_troll)
f_out = get_output_filepath(f)
with open(f_out, 'w+') as filehandle:
for tweet in collect.get_iterator():
try:
filehandle.write(json.dumps(tweet) + '''\n''')
except Exception as e:
#print(e)
pass
shutil.chown(f_out, group='smapp')
if __name__ == '__main__':
START_DATE = datetime.datetime.strptime('", year, "-", month, "-01', '%Y-%m-%d')
END_DATE = datetime.datetime.strptime('", year, "-", month, "-", day, "', '%Y-%m-%d')
OUT_DIR = '/scratch/ds3918/trolls/'
SEARCH_PATTERN = '/scratch/olympus/us_election_", n, "_2016/", where_in, "/us_election_", n, "_2016*'
TROLL_IDS = set()
print('START')
with open('/scratch/ds3918/trolls/data/all_troll_ids.txt', 'r') as inp:
for el in inp:
TROLL_IDS.add(el.strip())
print('There are {0} ids in TROLL_IDS'.format(len(TROLL_IDS)))
files = glob.glob(SEARCH_PATTERN)
files_to_sample = get_files_to_filter(files)
print('{} files to filter'.format(len(files_to_sample)))
for fi in files_to_sample:
filter_files(fi)
print('JOB DONE')")
string2 <- paste0("#!/bin/bash
#
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=10:00:00
#SBATCH --mem=5GB
#SBATCH --job-name=", n, "_", year, "_", month, "
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ds3918@nyu.edu
#SBATCH --output=logs/", n, "_", year, "_", month, ".out
cd /scratch/ds3918/trolls/code
LANG=en_US.utf8
PYTHONIOENCODING=UTF-8 python ", n, "_", year, "_", month, ".py > logs/output_", n, "_", year, "_", month, ".txt
exit 0;")
write(x = string1, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.py'))
write(x = string2, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.s'))
}
}
#-------------------------- Generate .py and .s for post Oct 10, 2016
for (n in names) {
for (dat in alldates) {
year <- substr(x = dat, start = 1, stop = 4)
month <- substr(x = dat, start = 6, stop = 7)
day <- substr(x = dat, start = 9, stop = 10)
if (dat %in% postdates) {
where_out = 'post'
where_in = 'data'
} else {
if (dat %in% predates) {
where_out = 'pre'
where_in = 'pre_october_2016'
} else {
cat('\n\nERROR: NOWHERE\n\n')
}
}
string1 <- paste0("import os, json, glob, datetime, shutil
from urllib.parse import urlparse
from multiprocessing import Pool
from tqdm import tqdm as tqdm
from smappdragon import JsonCollection
def get_date_from_file(f):
base = os.path.basename(f)
date = datetime.datetime.strptime(base.split('__')[1],'%m_%d_%Y')
return date
def get_files_to_filter(files):
files_to_sample = []
for f in tqdm(files):
basename = os.path.basename(f)
if '_pre' not in basename:
try:
f_date = get_date_from_file(f)
if START_DATE <= f_date <= END_DATE:
files_to_sample.append(f)
except:
pass
return files_to_sample
def is_from_troll(tweet):
if isinstance(tweet, dict) and tweet:
# Check if user is a troll.
if tweet['user']['id_str'] in TROLL_IDS:
return True
return False
def get_output_filepath(f):
collection_name = f.split('/')[3]
f_basename = os.path.basename(f).replace('.bz2', '')
new_collection_dir = os.path.join(OUT_DIR, collection_name)
os.makedirs(new_collection_dir, exist_ok=True)
shutil.chown(new_collection_dir, group='smapp')
f_out = os.path.join(new_collection_dir, f_basename)
return f_out
def filter_files(f):
date = get_date_from_file(f)
print('Working on {}'.format(date))
collect = JsonCollection(f, compression='bz2', throw_error=False, verbose=1)
collect.set_custom_filter(is_from_troll)
f_out = get_output_filepath(f)
with open(f_out, 'w+') as filehandle:
for tweet in collect.get_iterator():
try:
filehandle.write(json.dumps(tweet) + '''\n''')
except Exception as e:
#print(e)
pass
shutil.chown(f_out, group='smapp')
if __name__ == '__main__':
START_DATE = datetime.datetime.strptime('", year, "-", month, "-01', '%Y-%m-%d')
END_DATE = datetime.datetime.strptime('", year, "-", month, "-", day, "', '%Y-%m-%d')
OUT_DIR = '/scratch/ds3918/trolls/'
SEARCH_PATTERN = '/scratch/olympus/us_election_", n, "_2016/", where_in, "/us_election_", n, "_2016*'
TROLL_IDS = set()
print('START')
with open('/scratch/ds3918/trolls/data/all_troll_ids.txt', 'r') as inp:
for el in inp:
TROLL_IDS.add(el.strip())
print('There are {0} ids in TROLL_IDS'.format(len(TROLL_IDS)))
files = glob.glob(SEARCH_PATTERN)
files_to_sample = get_files_to_filter(files)
print('{} files to filter'.format(len(files_to_sample)))
for fi in files_to_sample:
filter_files(fi)
print('JOB DONE')")
string2 <- paste0("#!/bin/bash
#
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=10:00:00
#SBATCH --mem=5GB
#SBATCH --job-name=", n, "_", year, "_", month, "
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ds3918@nyu.edu
#SBATCH --output=logs/", n, "_", year, "_", month, ".out
cd /scratch/ds3918/trolls/code/", where_out, "
LANG=en_US.utf8
PYTHONIOENCODING=UTF-8 python ", n, "_", year, "_", month, ".py > logs/output_", n, "_", year, "_", month, ".txt
exit 0;")
write(x = string1, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.py'))
write(x = string2, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.s'))
}
}
rm(list = ls())
names <- c('marcorubio', 'mcmullin', 'misc', 'others', 'protests', 'rumors', 'tedcruz', 'general', 'trump', 'hillary', 'jebbush')
postdates <- c('2016-10-31', '2016-11-30', '2016-12-31', '2017-01-31', '2017-02-28', '2017-03-31', '2017-04-30',
'2017-05-31', '2017-06-30', '2017-07-31', '2017-08-31')
predates <- c('2015-01-31', '2015-02-28', '2015-03-31', '2015-04-30', '2015-05-31', '2015-06-30', '2015-07-31',
'2015-08-31', '2015-09-30', '2015-10-31', '2015-11-30', '2015-12-31', '2016-01-31', '2016-02-29',
'2016-03-31', '2016-04-30', '2016-05-31', '2016-06-30', '2016-07-31', '2016-08-31', '2016-09-30', '2016-10-18')
alldates <- unique(c(postdates, predates))[order(unique(c(postdates, predates)))]
#-------------------------- Generate .py and .s for post Oct 10, 2016
for (n in names) {
for (dat in alldates) {
year <- substr(x = dat, start = 1, stop = 4)
month <- substr(x = dat, start = 6, stop = 7)
day <- substr(x = dat, start = 9, stop = 10)
if (dat %in% postdates) {
where_out = 'post'
where_in = 'data'
} else {
if (dat %in% predates) {
where_out = 'pre'
where_in = 'pre_october_2016'
} else {
cat('\n\nERROR: NOWHERE\n\n')
}
}
string1 <- paste0("import os, json, glob, datetime, shutil
from urllib.parse import urlparse
from multiprocessing import Pool
from tqdm import tqdm as tqdm
from smappdragon import JsonCollection
def get_date_from_file(f):
base = os.path.basename(f)
date = datetime.datetime.strptime(base.split('__')[1],'%m_%d_%Y')
return date
def get_files_to_filter(files):
files_to_sample = []
for f in tqdm(files):
basename = os.path.basename(f)
if '_pre' not in basename:
try:
f_date = get_date_from_file(f)
if START_DATE <= f_date <= END_DATE:
files_to_sample.append(f)
except:
pass
return files_to_sample
def is_from_troll(tweet):
if isinstance(tweet, dict) and tweet:
# Check if user is a troll.
if tweet['user']['id_str'] in TROLL_IDS:
return True
return False
def get_output_filepath(f):
collection_name = f.split('/')[3]
f_basename = os.path.basename(f).replace('.bz2', '')
new_collection_dir = os.path.join(OUT_DIR, collection_name)
os.makedirs(new_collection_dir, exist_ok=True)
shutil.chown(new_collection_dir, group='smapp')
f_out = os.path.join(new_collection_dir, f_basename)
return f_out
def filter_files(f):
date = get_date_from_file(f)
print('Working on {}'.format(date))
collect = JsonCollection(f, compression='bz2', throw_error=False, verbose=1)
collect.set_custom_filter(is_from_troll)
f_out = get_output_filepath(f)
with open(f_out, 'w+') as filehandle:
for tweet in collect.get_iterator():
try:
filehandle.write(json.dumps(tweet) + '''\n''')
except Exception as e:
#print(e)
pass
shutil.chown(f_out, group='smapp')
if __name__ == '__main__':
START_DATE = datetime.datetime.strptime('", year, "-", month, "-01', '%Y-%m-%d')
END_DATE = datetime.datetime.strptime('", year, "-", month, "-", day, "', '%Y-%m-%d')
OUT_DIR = '/scratch/ds3918/trolls/'
SEARCH_PATTERN = '/scratch/olympus/us_election_", n, "_2016/", where_in, "/us_election_", n, "_2016*'
TROLL_IDS = set()
print('START')
with open('/scratch/ds3918/trolls/data/all_troll_ids.txt', 'r') as inp:
for el in inp:
TROLL_IDS.add(el.strip())
print('There are {0} ids in TROLL_IDS'.format(len(TROLL_IDS)))
files = glob.glob(SEARCH_PATTERN)
files_to_sample = get_files_to_filter(files)
print('{} files to filter'.format(len(files_to_sample)))
for fi in files_to_sample:
filter_files(fi)
print('JOB DONE')")
string2 <- paste0("#!/bin/bash
#
#SBATCH --nodes=1
#SBATCH --tasks-per-node=1
#SBATCH --cpus-per-task=1
#SBATCH --time=10:00:00
#SBATCH --mem=5GB
#SBATCH --job-name=", n, "_", year, "_", month, "
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --mail-user=ds3918@nyu.edu
#SBATCH --output=logs/", n, "_", year, "_", month, ".out
cd /scratch/ds3918/trolls/code/", where_out, "
LANG=en_US.utf8
PYTHONIOENCODING=UTF-8 python ", n, "_", year, "_", month, ".py > logs/output_", n, "_", year, "_", month, ".txt
exit 0;")
write(x = string1, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.py'))
write(x = string2, file = paste0('/Users/denisstukal/Dropbox/5_year_SPRING/trolls/code/get_tweets/', n, '/', where_out, '/', n, '_', year, '_', month,'.s'))
}
}
rm(list = ls())
library(caret)
library(doMC)
library(kernlab)
library(adabag)
library(rpart)
library(Matrix)
library(xgboost)
library(Ckmeans.1d.dp)
library(glmnet)
#-------------- LOAD MODELS --------------#
setwd('~/bot_applications/estimated_models')
models <- c("glmnet", "samme", "svm", "xgb")
for (i in 1:10) {
for (mod in models) {
load(paste0(mod, "_allper_botplus_bal_list_", i, ".RData"))
assign(x = paste0(mod, "_list_", i), value = get(paste0(mod, "_list")))
}
}
setwd('/Users/denisstukal/Dropbox/5_year_FALL/bots_current/Code/2nd_paper_bigdata/replication/bot_applications/estimated_models/')
models <- c("glmnet", "samme", "svm", "xgb")
for (i in 1:10) {
for (mod in models) {
load(paste0(mod, "_allper_botplus_bal_list_", i, ".RData"))
assign(x = paste0(mod, "_list_", i), value = get(paste0(mod, "_list")))
}
}
Sys.sleep(1)
rm(glmnet_list, samme_list, xgb_list, svm_list)
setwd('../train_data')
for (i in 1:10) {
load(paste0("allper_list_", i, "_botplus_bal.RData"))
assign(x = paste0("data_list_for_experiment_", i), value = get("data_list_for_experiment"))
}
Sys.sleep(1)
rm(data_list_for_experiment)
ls()
str(data_list_for_experiment_1)
names(data_list_for_experiment_1)
dat <- get(paste0('data_list_for_experiment_', i))
names(dat)
newdata <- data.frame('id' = 1, 'u' = 2)
dat <- get(paste0('data_list_for_experiment_', i))
#--- load model output
glmneto <- get(paste0("glmnet_list_", i))
sammeo <- get(paste0("samme_list_", i))
xgbo <- get(paste0("xgb_list_", i))
svmo <- get(paste0("svm_list_", i))
vars_to_remove <- setdiff(x = colnames(newdata), y = colnames(dat$train_x_trans))
vars_to_remove
as.Date('2017-04-27') - as.Date('2017-02-01') +
as.Date('2017-08-21') - as.Date('2017-06-10') +
as.Date('2017-12-31') - as.Date('2017-12-18')
365 - 170
(365 - 170)/30
#-----
1200 * 5 + 1175 * 7
174 + 159
4400 + 3500 + 1900 + 6778 + 1500 + 15000 + 7000 + 16800 + 52000 + 2000
(4400 + 3500 + 1900 + 6778 + 1500 + 15000 + 7000 + 16800 + 52000 + 2000) / 60
(4400 + 3500 + 1900 + 6778 + 1500 + 15000 + 7000 + 16800 + 52000 + 2000 + 15000) / 60
